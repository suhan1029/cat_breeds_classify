{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader, ConcatDataset\n",
    "from collections import Counter\n",
    "import torch.cuda.amp as amp\n",
    "from torch import nn, optim\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "import timm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGAN의 Generator 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# DCGAN의 Discriminator 정의\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_usage():\n",
    "    result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], \n",
    "                            stdout=subprocess.PIPE)\n",
    "    return int(result.stdout.decode('utf-8').strip())\n",
    "\n",
    "class DynamicDataLoader:\n",
    "    def __init__(self, dataset, batch_size=32, num_workers=4, pin_memory=True, prefetch_factor=2):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.prefetch_factor = prefetch_factor\n",
    "        self.loader = self.create_loader()\n",
    "        self.adjusting = False\n",
    "        self.target_gpu_usage = 95  # Target GPU usage in percent\n",
    "\n",
    "    def create_loader(self):\n",
    "        return DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, \n",
    "                          pin_memory=self.pin_memory, prefetch_factor=self.prefetch_factor, persistent_workers=True)\n",
    "\n",
    "    def adjust_num_workers(self):\n",
    "        while self.adjusting:\n",
    "            gpu_usage = get_gpu_usage()\n",
    "            print(f\"Current GPU usage: {gpu_usage}%\")\n",
    "            if gpu_usage < self.target_gpu_usage - 10 and self.num_workers < 16:\n",
    "                self.num_workers += 1\n",
    "                print(f\"Increasing num_workers to {self.num_workers}\")\n",
    "            elif gpu_usage > self.target_gpu_usage + 10 and self.num_workers > 1:\n",
    "                self.num_workers -= 1\n",
    "                print(f\"Decreasing num_workers to {self.num_workers}\")\n",
    "            self.loader = self.create_loader()\n",
    "            time.sleep(20)\n",
    "\n",
    "    def start_adjusting(self):\n",
    "        self.adjusting = True\n",
    "        self.adjust_thread = threading.Thread(target=self.adjust_num_workers)\n",
    "        self.adjust_thread.start()\n",
    "\n",
    "    def stop_adjusting(self):\n",
    "        self.adjusting = False\n",
    "        self.adjust_thread.join()\n",
    "\n",
    "    def get_loader(self):\n",
    "        return self.loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "batch_size = 64\n",
    "image_size = 64\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 3\n",
    "num_epochs = 50\n",
    "lr = 0.0001\n",
    "beta1 = 0.5\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000})\n",
      "Splitting dataset into training and validation sets...\n",
      "Training and validation data are ready.\n"
     ]
    }
   ],
   "source": [
    "base_dir = './cat_faces/'\n",
    "\n",
    "# 데이터 전처리 및 증강\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(331),  # 이미지를 331로 리사이즈\n",
    "        transforms.CenterCrop(299),  # 299x299로 중심 자르기\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),  # 추가적인 데이터 증강\n",
    "        transforms.RandomGrayscale(p=0.2),  # 추가적인 데이터 증강\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(331),\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 전체 데이터셋 로드\n",
    "full_dataset = datasets.ImageFolder(base_dir, transform=data_transforms['train'])\n",
    "\n",
    "# 클래스별 이미지 개수 출력\n",
    "class_counts = Counter([full_dataset.targets[i] for i in range(len(full_dataset))])\n",
    "print(\"Original class distribution:\", class_counts)\n",
    "\n",
    "print(\"Splitting dataset into training and validation sets...\")\n",
    "# 데이터셋을 훈련과 검증 세트로 나누기 (예: 80% 훈련, 20% 검증)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# 훈련 데이터셋과 검증 데이터셋 각각에 다른 변환 적용\n",
    "train_dataset.dataset.transform = data_transforms['train']\n",
    "val_dataset.dataset.transform = data_transforms['val']\n",
    "\n",
    "# DynamicDataLoader 사용\n",
    "dynamic_loader = DynamicDataLoader(train_dataset, batch_size=32, num_workers=4, pin_memory=True, prefetch_factor=4)\n",
    "dynamic_loader.start_adjusting()\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=4, persistent_workers=True)\n",
    "\n",
    "dataloaders = {'train': dynamic_loader.get_loader(), 'val': val_loader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "print(\"Training and validation data are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU usage: 9%\n",
      "Increasing num_workers to 5\n",
      "[0/50][0/141] Loss_D: 1.5440 Loss_G: 1.6485 D(x): 0.5070 D(G(z)): 0.5655 / 0.1976\n",
      "[0/50][50/141] Loss_D: 0.0340 Loss_G: 6.8432 D(x): 0.9884 D(G(z)): 0.0217 / 0.0012\n",
      "[0/50][100/141] Loss_D: 0.0399 Loss_G: 7.8357 D(x): 0.9866 D(G(z)): 0.0255 / 0.0004\n",
      "[1/50][0/141] Loss_D: 0.3478 Loss_G: 18.5285 D(x): 0.9956 D(G(z)): 0.2731 / 0.0000\n",
      "[1/50][50/141] Loss_D: 0.2426 Loss_G: 6.3566 D(x): 0.8489 D(G(z)): 0.0079 / 0.0064\n",
      "[1/50][100/141] Loss_D: 0.4415 Loss_G: 4.6824 D(x): 0.9111 D(G(z)): 0.2502 / 0.0167\n",
      "[2/50][0/141] Loss_D: 0.4095 Loss_G: 3.3509 D(x): 0.7474 D(G(z)): 0.0504 / 0.0436\n",
      "[2/50][50/141] Loss_D: 0.0751 Loss_G: 5.9067 D(x): 0.9661 D(G(z)): 0.0364 / 0.0040\n",
      "[2/50][100/141] Loss_D: 0.2791 Loss_G: 4.0427 D(x): 0.9004 D(G(z)): 0.1343 / 0.0218\n",
      "[3/50][0/141] Loss_D: 0.2365 Loss_G: 3.8679 D(x): 0.9151 D(G(z)): 0.1261 / 0.0270\n",
      "Current GPU usage: 37%\n",
      "Increasing num_workers to 6\n",
      "[3/50][50/141] Loss_D: 0.3050 Loss_G: 2.3236 D(x): 0.8105 D(G(z)): 0.0285 / 0.1431\n",
      "[3/50][100/141] Loss_D: 0.1726 Loss_G: 4.8621 D(x): 0.9351 D(G(z)): 0.0836 / 0.0137\n",
      "[4/50][0/141] Loss_D: 0.2055 Loss_G: 5.3198 D(x): 0.9361 D(G(z)): 0.1162 / 0.0080\n",
      "[4/50][50/141] Loss_D: 0.6217 Loss_G: 9.9470 D(x): 0.9737 D(G(z)): 0.4125 / 0.0002\n",
      "[4/50][100/141] Loss_D: 0.2588 Loss_G: 3.3915 D(x): 0.8431 D(G(z)): 0.0603 / 0.0492\n",
      "[5/50][0/141] Loss_D: 0.4131 Loss_G: 3.3399 D(x): 0.8693 D(G(z)): 0.2074 / 0.0449\n",
      "[5/50][50/141] Loss_D: 0.3842 Loss_G: 5.3966 D(x): 0.7650 D(G(z)): 0.0125 / 0.0105\n",
      "[5/50][100/141] Loss_D: 0.2969 Loss_G: 3.7769 D(x): 0.8121 D(G(z)): 0.0402 / 0.0313\n",
      "[6/50][0/141] Loss_D: 0.1689 Loss_G: 3.7730 D(x): 0.9453 D(G(z)): 0.0979 / 0.0322\n",
      "[6/50][50/141] Loss_D: 0.3107 Loss_G: 3.3424 D(x): 0.8642 D(G(z)): 0.1166 / 0.0703\n",
      "Current GPU usage: 39%\n",
      "Increasing num_workers to 7\n",
      "[6/50][100/141] Loss_D: 0.3185 Loss_G: 5.4309 D(x): 0.7883 D(G(z)): 0.0217 / 0.0147\n",
      "[7/50][0/141] Loss_D: 0.2013 Loss_G: 5.2147 D(x): 0.8565 D(G(z)): 0.0216 / 0.0097\n",
      "[7/50][50/141] Loss_D: 0.7603 Loss_G: 5.7242 D(x): 0.5620 D(G(z)): 0.0021 / 0.0075\n",
      "[7/50][100/141] Loss_D: 0.1975 Loss_G: 4.4578 D(x): 0.8845 D(G(z)): 0.0538 / 0.0209\n",
      "[8/50][0/141] Loss_D: 0.3227 Loss_G: 6.0416 D(x): 0.9487 D(G(z)): 0.2056 / 0.0052\n",
      "[8/50][50/141] Loss_D: 0.4968 Loss_G: 1.7676 D(x): 0.6886 D(G(z)): 0.0489 / 0.2304\n",
      "[8/50][100/141] Loss_D: 0.4319 Loss_G: 3.6690 D(x): 0.7354 D(G(z)): 0.0241 / 0.0593\n",
      "[9/50][0/141] Loss_D: 0.2317 Loss_G: 4.1801 D(x): 0.9590 D(G(z)): 0.1600 / 0.0220\n",
      "[9/50][50/141] Loss_D: 0.8017 Loss_G: 1.6158 D(x): 0.5308 D(G(z)): 0.0077 / 0.2508\n",
      "[9/50][100/141] Loss_D: 0.0883 Loss_G: 3.3664 D(x): 0.9699 D(G(z)): 0.0529 / 0.0511\n",
      "[10/50][0/141] Loss_D: 0.1668 Loss_G: 4.2136 D(x): 0.9007 D(G(z)): 0.0523 / 0.0200\n",
      "Current GPU usage: 29%\n",
      "Increasing num_workers to 8\n",
      "[10/50][50/141] Loss_D: 0.6502 Loss_G: 4.1125 D(x): 0.9398 D(G(z)): 0.3934 / 0.0325\n",
      "[10/50][100/141] Loss_D: 0.1419 Loss_G: 4.2702 D(x): 0.9487 D(G(z)): 0.0816 / 0.0179\n",
      "[11/50][0/141] Loss_D: 2.0342 Loss_G: 3.7504 D(x): 0.2257 D(G(z)): 0.0010 / 0.0677\n",
      "[11/50][50/141] Loss_D: 0.1533 Loss_G: 3.5471 D(x): 0.9026 D(G(z)): 0.0431 / 0.0412\n",
      "[11/50][100/141] Loss_D: 0.2445 Loss_G: 2.4824 D(x): 0.8472 D(G(z)): 0.0607 / 0.1096\n",
      "[12/50][0/141] Loss_D: 1.0187 Loss_G: 3.4621 D(x): 0.4554 D(G(z)): 0.0174 / 0.0647\n",
      "[12/50][50/141] Loss_D: 0.2851 Loss_G: 5.5488 D(x): 0.9767 D(G(z)): 0.2179 / 0.0053\n",
      "[12/50][100/141] Loss_D: 0.1954 Loss_G: 3.8070 D(x): 0.9758 D(G(z)): 0.1496 / 0.0312\n",
      "[13/50][0/141] Loss_D: 0.6820 Loss_G: 1.5283 D(x): 0.6086 D(G(z)): 0.0801 / 0.2795\n",
      "[13/50][50/141] Loss_D: 0.1999 Loss_G: 3.5182 D(x): 0.9271 D(G(z)): 0.1078 / 0.0393\n",
      "Current GPU usage: 37%\n",
      "Increasing num_workers to 9\n",
      "[13/50][100/141] Loss_D: 0.3470 Loss_G: 3.9219 D(x): 0.8933 D(G(z)): 0.1905 / 0.0250\n",
      "[14/50][0/141] Loss_D: 0.8092 Loss_G: 2.2292 D(x): 0.5330 D(G(z)): 0.0566 / 0.1536\n",
      "[14/50][50/141] Loss_D: 0.2673 Loss_G: 3.3361 D(x): 0.8347 D(G(z)): 0.0664 / 0.0418\n",
      "[14/50][100/141] Loss_D: 0.2683 Loss_G: 4.2450 D(x): 0.9180 D(G(z)): 0.1529 / 0.0178\n",
      "[15/50][0/141] Loss_D: 0.2772 Loss_G: 3.6021 D(x): 0.9695 D(G(z)): 0.2038 / 0.0361\n",
      "[15/50][50/141] Loss_D: 0.6062 Loss_G: 2.4331 D(x): 0.7780 D(G(z)): 0.2588 / 0.1230\n",
      "[15/50][100/141] Loss_D: 0.2582 Loss_G: 5.2837 D(x): 0.9626 D(G(z)): 0.1862 / 0.0066\n",
      "[16/50][0/141] Loss_D: 0.8466 Loss_G: 4.2415 D(x): 0.9349 D(G(z)): 0.4841 / 0.0255\n",
      "[16/50][50/141] Loss_D: 0.4228 Loss_G: 4.4397 D(x): 0.9633 D(G(z)): 0.2924 / 0.0173\n",
      "[16/50][100/141] Loss_D: 1.1275 Loss_G: 7.9589 D(x): 0.9757 D(G(z)): 0.6112 / 0.0006\n",
      "[17/50][0/141] Loss_D: 0.3951 Loss_G: 4.6654 D(x): 0.7244 D(G(z)): 0.0237 / 0.0140\n",
      "Current GPU usage: 34%\n",
      "Increasing num_workers to 10\n",
      "[17/50][50/141] Loss_D: 0.1835 Loss_G: 2.9619 D(x): 0.8748 D(G(z)): 0.0381 / 0.0676\n",
      "[17/50][100/141] Loss_D: 1.0866 Loss_G: 8.0181 D(x): 0.9672 D(G(z)): 0.5948 / 0.0006\n",
      "[18/50][0/141] Loss_D: 0.8291 Loss_G: 5.9254 D(x): 0.9467 D(G(z)): 0.4746 / 0.0053\n",
      "[18/50][50/141] Loss_D: 0.2188 Loss_G: 3.3937 D(x): 0.9066 D(G(z)): 0.0958 / 0.0453\n",
      "[18/50][100/141] Loss_D: 0.6148 Loss_G: 1.8699 D(x): 0.6318 D(G(z)): 0.0767 / 0.1911\n",
      "[19/50][0/141] Loss_D: 0.1523 Loss_G: 4.2797 D(x): 0.9542 D(G(z)): 0.0961 / 0.0190\n",
      "[19/50][50/141] Loss_D: 0.1294 Loss_G: 3.9015 D(x): 0.9886 D(G(z)): 0.1080 / 0.0270\n",
      "[19/50][100/141] Loss_D: 0.2022 Loss_G: 4.4742 D(x): 0.9347 D(G(z)): 0.1184 / 0.0159\n",
      "[20/50][0/141] Loss_D: 0.1421 Loss_G: 4.2149 D(x): 0.9727 D(G(z)): 0.1037 / 0.0192\n",
      "[20/50][50/141] Loss_D: 0.0923 Loss_G: 3.6222 D(x): 0.9692 D(G(z)): 0.0576 / 0.0372\n",
      "[20/50][100/141] Loss_D: 0.9711 Loss_G: 2.6099 D(x): 0.4654 D(G(z)): 0.0142 / 0.1253\n",
      "Current GPU usage: 36%\n",
      "Increasing num_workers to 11\n",
      "[21/50][0/141] Loss_D: 0.2785 Loss_G: 3.6701 D(x): 0.8492 D(G(z)): 0.0864 / 0.0354\n",
      "[21/50][50/141] Loss_D: 0.2079 Loss_G: 3.2383 D(x): 0.8641 D(G(z)): 0.0498 / 0.0519\n",
      "[21/50][100/141] Loss_D: 0.1535 Loss_G: 3.5463 D(x): 0.9276 D(G(z)): 0.0656 / 0.0396\n",
      "[22/50][0/141] Loss_D: 0.4066 Loss_G: 4.1892 D(x): 0.7084 D(G(z)): 0.0224 / 0.0253\n",
      "[22/50][50/141] Loss_D: 0.1397 Loss_G: 4.0060 D(x): 0.9464 D(G(z)): 0.0775 / 0.0243\n",
      "[22/50][100/141] Loss_D: 0.6361 Loss_G: 2.4943 D(x): 0.6748 D(G(z)): 0.1492 / 0.1269\n",
      "[23/50][0/141] Loss_D: 0.2671 Loss_G: 3.4573 D(x): 0.9298 D(G(z)): 0.1631 / 0.0438\n",
      "[23/50][50/141] Loss_D: 0.4813 Loss_G: 5.7800 D(x): 0.9855 D(G(z)): 0.3484 / 0.0042\n",
      "[23/50][100/141] Loss_D: 0.2550 Loss_G: 4.7468 D(x): 0.9640 D(G(z)): 0.1872 / 0.0121\n",
      "[24/50][0/141] Loss_D: 0.9856 Loss_G: 9.1074 D(x): 0.9903 D(G(z)): 0.5536 / 0.0002\n",
      "Current GPU usage: 40%\n",
      "Increasing num_workers to 12\n",
      "[24/50][50/141] Loss_D: 0.2964 Loss_G: 4.5391 D(x): 0.9815 D(G(z)): 0.2283 / 0.0159\n",
      "[24/50][100/141] Loss_D: 0.3463 Loss_G: 1.2991 D(x): 0.8885 D(G(z)): 0.1815 / 0.3159\n",
      "[25/50][0/141] Loss_D: 0.8449 Loss_G: 6.0556 D(x): 0.9926 D(G(z)): 0.5071 / 0.0049\n",
      "[25/50][50/141] Loss_D: 0.1075 Loss_G: 3.7609 D(x): 0.9488 D(G(z)): 0.0507 / 0.0297\n",
      "[25/50][100/141] Loss_D: 0.0727 Loss_G: 4.4970 D(x): 0.9877 D(G(z)): 0.0577 / 0.0144\n",
      "[26/50][0/141] Loss_D: 0.2543 Loss_G: 3.9155 D(x): 0.8653 D(G(z)): 0.0834 / 0.0315\n",
      "[26/50][50/141] Loss_D: 0.2034 Loss_G: 4.6759 D(x): 0.9590 D(G(z)): 0.1413 / 0.0128\n",
      "[26/50][100/141] Loss_D: 0.8000 Loss_G: 8.3900 D(x): 0.9421 D(G(z)): 0.4742 / 0.0005\n",
      "[27/50][0/141] Loss_D: 0.5777 Loss_G: 5.3972 D(x): 0.9041 D(G(z)): 0.3314 / 0.0081\n",
      "[27/50][50/141] Loss_D: 1.6605 Loss_G: 9.3045 D(x): 0.9959 D(G(z)): 0.7456 / 0.0002\n",
      "Current GPU usage: 37%\n",
      "Increasing num_workers to 13\n",
      "[27/50][100/141] Loss_D: 0.0830 Loss_G: 4.7908 D(x): 0.9642 D(G(z)): 0.0445 / 0.0111\n",
      "[28/50][0/141] Loss_D: 0.5208 Loss_G: 6.8788 D(x): 0.9637 D(G(z)): 0.3577 / 0.0016\n",
      "[28/50][50/141] Loss_D: 0.2392 Loss_G: 3.7766 D(x): 0.9282 D(G(z)): 0.1343 / 0.0368\n",
      "[28/50][100/141] Loss_D: 0.0515 Loss_G: 5.3667 D(x): 0.9896 D(G(z)): 0.0395 / 0.0071\n",
      "[29/50][0/141] Loss_D: 0.1471 Loss_G: 4.1209 D(x): 0.9703 D(G(z)): 0.1041 / 0.0205\n",
      "[29/50][50/141] Loss_D: 0.1780 Loss_G: 3.9382 D(x): 0.9367 D(G(z)): 0.0987 / 0.0277\n",
      "[29/50][100/141] Loss_D: 0.0440 Loss_G: 4.0673 D(x): 0.9776 D(G(z)): 0.0204 / 0.0246\n",
      "[30/50][0/141] Loss_D: 0.0557 Loss_G: 3.9330 D(x): 0.9618 D(G(z)): 0.0156 / 0.0289\n",
      "[30/50][50/141] Loss_D: 0.5662 Loss_G: 3.7247 D(x): 0.6365 D(G(z)): 0.0134 / 0.0460\n",
      "[30/50][100/141] Loss_D: 0.7257 Loss_G: 3.0803 D(x): 0.5425 D(G(z)): 0.0081 / 0.0827\n",
      "[31/50][0/141] Loss_D: 0.1929 Loss_G: 2.7764 D(x): 0.8853 D(G(z)): 0.0560 / 0.0957\n",
      "Current GPU usage: 36%\n",
      "Increasing num_workers to 14\n",
      "[31/50][50/141] Loss_D: 0.0823 Loss_G: 4.3253 D(x): 0.9792 D(G(z)): 0.0573 / 0.0201\n",
      "[31/50][100/141] Loss_D: 0.0550 Loss_G: 4.9362 D(x): 0.9780 D(G(z)): 0.0314 / 0.0118\n",
      "[32/50][0/141] Loss_D: 0.3001 Loss_G: 5.5263 D(x): 0.9822 D(G(z)): 0.2193 / 0.0062\n",
      "[32/50][50/141] Loss_D: 0.4165 Loss_G: 3.4173 D(x): 0.7206 D(G(z)): 0.0379 / 0.0504\n",
      "[32/50][100/141] Loss_D: 0.4612 Loss_G: 3.7956 D(x): 0.8038 D(G(z)): 0.1724 / 0.0466\n",
      "[33/50][0/141] Loss_D: 0.1367 Loss_G: 3.8911 D(x): 0.9194 D(G(z)): 0.0470 / 0.0264\n",
      "[33/50][50/141] Loss_D: 0.1284 Loss_G: 3.5803 D(x): 0.9068 D(G(z)): 0.0254 / 0.0372\n",
      "[33/50][100/141] Loss_D: 0.2770 Loss_G: 2.5984 D(x): 0.8011 D(G(z)): 0.0266 / 0.1121\n",
      "[34/50][0/141] Loss_D: 0.0437 Loss_G: 4.4590 D(x): 0.9818 D(G(z)): 0.0247 / 0.0162\n",
      "[34/50][50/141] Loss_D: 0.1945 Loss_G: 5.9796 D(x): 0.9952 D(G(z)): 0.1625 / 0.0033\n",
      "Current GPU usage: 42%\n",
      "Increasing num_workers to 15\n",
      "[34/50][100/141] Loss_D: 0.3936 Loss_G: 4.6715 D(x): 0.7291 D(G(z)): 0.0427 / 0.0209\n",
      "[35/50][0/141] Loss_D: 0.4756 Loss_G: 1.7180 D(x): 0.7005 D(G(z)): 0.0395 / 0.2260\n",
      "[35/50][50/141] Loss_D: 0.2049 Loss_G: 4.6840 D(x): 0.9593 D(G(z)): 0.1426 / 0.0127\n",
      "[35/50][100/141] Loss_D: 0.4778 Loss_G: 2.9463 D(x): 0.9736 D(G(z)): 0.3167 / 0.0948\n",
      "[36/50][0/141] Loss_D: 0.1810 Loss_G: 5.0008 D(x): 0.9838 D(G(z)): 0.1427 / 0.0110\n",
      "[36/50][50/141] Loss_D: 0.2738 Loss_G: 3.7219 D(x): 0.8159 D(G(z)): 0.0473 / 0.0392\n",
      "[36/50][100/141] Loss_D: 0.1569 Loss_G: 3.5357 D(x): 0.8902 D(G(z)): 0.0295 / 0.0437\n",
      "[37/50][0/141] Loss_D: 0.1223 Loss_G: 4.6192 D(x): 0.9919 D(G(z)): 0.1022 / 0.0150\n",
      "[37/50][50/141] Loss_D: 1.6376 Loss_G: 11.8810 D(x): 0.9979 D(G(z)): 0.7389 / 0.0000\n",
      "[37/50][100/141] Loss_D: 0.1343 Loss_G: 3.4606 D(x): 0.9070 D(G(z)): 0.0296 / 0.0419\n",
      "Current GPU usage: 38%\n",
      "Increasing num_workers to 16\n",
      "[38/50][0/141] Loss_D: 0.3687 Loss_G: 4.8710 D(x): 0.9847 D(G(z)): 0.2682 / 0.0120\n",
      "[38/50][50/141] Loss_D: 0.1165 Loss_G: 4.8842 D(x): 0.9700 D(G(z)): 0.0783 / 0.0119\n",
      "[38/50][100/141] Loss_D: 0.1010 Loss_G: 4.4927 D(x): 0.9663 D(G(z)): 0.0615 / 0.0165\n",
      "[39/50][0/141] Loss_D: 1.0707 Loss_G: 3.6907 D(x): 0.4793 D(G(z)): 0.0343 / 0.0749\n",
      "[39/50][50/141] Loss_D: 0.2011 Loss_G: 2.5553 D(x): 0.8843 D(G(z)): 0.0644 / 0.0942\n",
      "[39/50][100/141] Loss_D: 0.1061 Loss_G: 4.4234 D(x): 0.9178 D(G(z)): 0.0168 / 0.0187\n",
      "[40/50][0/141] Loss_D: 0.2936 Loss_G: 4.4162 D(x): 0.9467 D(G(z)): 0.1921 / 0.0215\n",
      "[40/50][50/141] Loss_D: 0.1094 Loss_G: 4.0503 D(x): 0.9082 D(G(z)): 0.0081 / 0.0249\n",
      "[40/50][100/141] Loss_D: 0.1646 Loss_G: 2.6496 D(x): 0.8945 D(G(z)): 0.0406 / 0.0953\n",
      "[41/50][0/141] Loss_D: 0.1642 Loss_G: 4.8438 D(x): 0.9787 D(G(z)): 0.1176 / 0.0140\n",
      "Current GPU usage: 36%\n",
      "[41/50][50/141] Loss_D: 0.0247 Loss_G: 4.6359 D(x): 0.9896 D(G(z)): 0.0140 / 0.0136\n",
      "[41/50][100/141] Loss_D: 0.0403 Loss_G: 4.3052 D(x): 0.9797 D(G(z)): 0.0191 / 0.0206\n",
      "[42/50][0/141] Loss_D: 0.0501 Loss_G: 3.8202 D(x): 0.9671 D(G(z)): 0.0158 / 0.0325\n",
      "[42/50][50/141] Loss_D: 0.2165 Loss_G: 3.5033 D(x): 0.8822 D(G(z)): 0.0745 / 0.0448\n",
      "[42/50][100/141] Loss_D: 0.1640 Loss_G: 3.4031 D(x): 0.8756 D(G(z)): 0.0199 / 0.0522\n",
      "[43/50][0/141] Loss_D: 0.1752 Loss_G: 6.3583 D(x): 0.8692 D(G(z)): 0.0172 / 0.0041\n",
      "[43/50][50/141] Loss_D: 0.1232 Loss_G: 3.6516 D(x): 0.9019 D(G(z)): 0.0122 / 0.0412\n",
      "[43/50][100/141] Loss_D: 0.6206 Loss_G: 0.4923 D(x): 0.6453 D(G(z)): 0.0347 / 0.6642\n",
      "[44/50][0/141] Loss_D: 0.1028 Loss_G: 3.9506 D(x): 0.9615 D(G(z)): 0.0584 / 0.0326\n",
      "[44/50][50/141] Loss_D: 0.1570 Loss_G: 5.5874 D(x): 0.9847 D(G(z)): 0.1203 / 0.0060\n",
      "[44/50][100/141] Loss_D: 0.0823 Loss_G: 4.3090 D(x): 0.9816 D(G(z)): 0.0601 / 0.0172\n",
      "Current GPU usage: 33%\n",
      "[45/50][0/141] Loss_D: 0.2440 Loss_G: 3.0881 D(x): 0.8896 D(G(z)): 0.0996 / 0.0745\n",
      "[45/50][50/141] Loss_D: 0.0589 Loss_G: 4.8668 D(x): 0.9798 D(G(z)): 0.0366 / 0.0112\n",
      "[45/50][100/141] Loss_D: 0.1902 Loss_G: 5.7657 D(x): 0.9800 D(G(z)): 0.1413 / 0.0044\n",
      "[46/50][0/141] Loss_D: 0.2039 Loss_G: 4.0136 D(x): 0.8975 D(G(z)): 0.0754 / 0.0284\n",
      "[46/50][50/141] Loss_D: 1.3969 Loss_G: 2.7187 D(x): 0.3269 D(G(z)): 0.0007 / 0.1719\n",
      "[46/50][100/141] Loss_D: 0.0686 Loss_G: 4.1066 D(x): 0.9557 D(G(z)): 0.0211 / 0.0280\n",
      "[47/50][0/141] Loss_D: 0.4238 Loss_G: 5.6420 D(x): 0.9933 D(G(z)): 0.2937 / 0.0078\n",
      "[47/50][50/141] Loss_D: 0.0929 Loss_G: 4.4838 D(x): 0.9489 D(G(z)): 0.0373 / 0.0216\n",
      "[47/50][100/141] Loss_D: 0.2007 Loss_G: 3.6254 D(x): 0.8880 D(G(z)): 0.0603 / 0.0468\n",
      "[48/50][0/141] Loss_D: 0.0966 Loss_G: 4.9947 D(x): 0.9792 D(G(z)): 0.0636 / 0.0108\n",
      "Current GPU usage: 34%\n",
      "[48/50][50/141] Loss_D: 0.1051 Loss_G: 4.3884 D(x): 0.9333 D(G(z)): 0.0297 / 0.0188\n",
      "[48/50][100/141] Loss_D: 0.3632 Loss_G: 1.8681 D(x): 0.7388 D(G(z)): 0.0040 / 0.2991\n",
      "[49/50][0/141] Loss_D: 0.3060 Loss_G: 5.3784 D(x): 0.7833 D(G(z)): 0.0133 / 0.0107\n",
      "[49/50][50/141] Loss_D: 0.1087 Loss_G: 3.7330 D(x): 0.9314 D(G(z)): 0.0339 / 0.0342\n",
      "[49/50][100/141] Loss_D: 0.3830 Loss_G: 4.3141 D(x): 0.8890 D(G(z)): 0.1956 / 0.0282\n"
     ]
    }
   ],
   "source": [
    "# DCGAN 학습\n",
    "dataset = datasets.ImageFolder(root=base_dir,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 모델 초기화\n",
    "netG = Generator(nz, ngf, nc).to(device)\n",
    "netD = Discriminator(nc, ndf).to(device)\n",
    "\n",
    "# 손실 함수와 최적화 설정\n",
    "criterion = nn.BCELoss()\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # 실제 이미지로 Discriminator 학습\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # 가짜 이미지로 Discriminator 학습\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Generator 학습\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        output = netD(fake).view(-1)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}] '\n",
    "                  f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n",
    "                  f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
    "\n",
    "    # 학습 진행 상황 시각화\n",
    "    if epoch % 10 == 0:\n",
    "        vutils.save_image(real_cpu, f'real_samples_epoch_{epoch}.png', normalize=True)\n",
    "        fake = netG(fixed_noise)\n",
    "        vutils.save_image(fake.detach(), f'fake_samples_epoch_{epoch}.png', normalize=True)\n",
    "\n",
    "# 최종 Generator 저장\n",
    "torch.save(netG.state_dict(), 'dcgan_generator.pth')\n",
    "\n",
    "# 생성된 이미지 저장 경로 설정\n",
    "gen_images_dir = './generated_images/'\n",
    "os.makedirs(gen_images_dir, exist_ok=True)\n",
    "\n",
    "# 학습된 Generator 로드\n",
    "netG.load_state_dict(torch.load('dcgan_generator.pth'))\n",
    "netG.eval()\n",
    "\n",
    "# 각 품종에 대한 새로운 이미지 생성 및 저장\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(gen_images_dir, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    for i in range(100):  # 각 품종당 100장 생성\n",
    "        noise = torch.randn(1, nz, 1, 1, device=device)\n",
    "        with torch.no_grad():\n",
    "            fake = netG(noise).detach().cpu()\n",
    "        fake_image = (fake[0] * 0.5 + 0.5) * 255\n",
    "        fake_image = fake_image.permute(1, 2, 0).numpy().astype(np.uint8)\n",
    "        img = Image.fromarray(fake_image)\n",
    "        img.save(os.path.join(class_dir, f'fake_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터셋에 생성된 이미지 추가\n",
    "new_data_transforms = transforms.Compose([\n",
    "    transforms.Resize(331),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "generated_dataset = datasets.ImageFolder(root=gen_images_dir, transform=new_data_transforms)\n",
    "full_dataset = ConcatDataset([full_dataset, generated_dataset])\n",
    "\n",
    "# 기존 데이터셋을 다시 분할\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataset.dataset.transform = data_transforms['train']\n",
    "val_dataset.dataset.transform = data_transforms['val']\n",
    "\n",
    "dynamic_loader = DynamicDataLoader(train_dataset, batch_size=32, num_workers=4, pin_memory=True, prefetch_factor=4)\n",
    "dynamic_loader.start_adjusting()\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=4, persistent_workers=True)\n",
    "\n",
    "dataloaders = {'train': dynamic_loader.get_loader(), 'val': val_loader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "class_names = full_dataset.datasets[0].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU usage: 24%\n",
      "Increasing num_workers to 5\n",
      "Output features: 98304\n"
     ]
    }
   ],
   "source": [
    "# InceptionResNetV2 모델 로드\n",
    "base_model = timm.create_model('inception_resnet_v2', pretrained=True).to(device)\n",
    "\n",
    "# 모델의 출력 크기를 확인\n",
    "dummy_input = torch.randn(1, 3, 299, 299).to(device)\n",
    "base_model.eval()\n",
    "with torch.no_grad():\n",
    "    dummy_output = base_model.forward_features(dummy_input)\n",
    "    num_features = dummy_output.shape[1] * dummy_output.shape[2] * dummy_output.shape[3]\n",
    "    print(f'Output features: {num_features}')\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, base_model, num_classes):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(num_features, num_classes)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.base_model.forward_features(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = CustomModel(base_model, len(class_names)).to(device)\n",
    "\n",
    "# 모든 레이어의 requires_grad를 True로 설정하여 고정 해제\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scaler = amp.GradScaler()\n",
    "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "Current GPU usage: 8%\n",
      "Current GPU usage: 72%\n",
      "Increasing num_workers to 6\n",
      "Current GPU usage: 78%\n",
      "Current GPU usage: 74%\n",
      "Increasing num_workers to 7\n",
      "train Loss: 1.6805 Acc: 0.3949\n",
      "Current GPU usage: 5%\n",
      "val Loss: 1.4076 Acc: 0.4796\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "Current GPU usage: 71%\n",
      "Increasing num_workers to 8\n",
      "Current GPU usage: 55%\n",
      "Current GPU usage: 84%\n",
      "Increasing num_workers to 9\n",
      "Current GPU usage: 80%\n",
      "train Loss: 1.0689 Acc: 0.6034\n",
      "val Loss: 1.3671 Acc: 0.4926\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "Current GPU usage: 75%\n",
      "Increasing num_workers to 10\n",
      "Current GPU usage: 85%\n",
      "Current GPU usage: 76%\n",
      "Increasing num_workers to 11\n",
      "Current GPU usage: 69%\n",
      "train Loss: 0.6540 Acc: 0.7549\n",
      "val Loss: 1.5434 Acc: 0.4986\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "Current GPU usage: 71%\n",
      "Increasing num_workers to 12\n",
      "Current GPU usage: 68%\n",
      "Current GPU usage: 59%\n",
      "Increasing num_workers to 13\n",
      "Current GPU usage: 73%\n",
      "train Loss: 0.4709 Acc: 0.8240\n",
      "val Loss: 1.8308 Acc: 0.4949\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "Current GPU usage: 65%\n",
      "Increasing num_workers to 14\n",
      "Current GPU usage: 74%\n",
      "Current GPU usage: 59%\n",
      "Increasing num_workers to 15\n",
      "Current GPU usage: 73%\n",
      "train Loss: 0.4209 Acc: 0.8374\n",
      "val Loss: 1.9649 Acc: 0.4954\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "Current GPU usage: 63%\n",
      "Increasing num_workers to 16\n",
      "Current GPU usage: 69%\n",
      "Current GPU usage: 73%\n",
      "Current GPU usage: 74%\n",
      "train Loss: 0.4111 Acc: 0.8398\n",
      "val Loss: 1.9199 Acc: 0.5079\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "Current GPU usage: 11%\n",
      "Current GPU usage: 60%\n",
      "Current GPU usage: 81%\n",
      "Current GPU usage: 76%\n",
      "train Loss: 0.4092 Acc: 0.8429\n",
      "Current GPU usage: 57%\n",
      "val Loss: 2.0951 Acc: 0.4796\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "Current GPU usage: 83%\n",
      "Current GPU usage: 66%\n",
      "Current GPU usage: 55%\n",
      "Current GPU usage: 62%\n",
      "train Loss: 0.4682 Acc: 0.8236\n",
      "val Loss: 2.1349 Acc: 0.4889\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "Current GPU usage: 52%\n",
      "Current GPU usage: 58%\n",
      "Current GPU usage: 57%\n",
      "Current GPU usage: 51%\n",
      "train Loss: 0.4713 Acc: 0.8206\n",
      "Current GPU usage: 54%\n",
      "val Loss: 2.0391 Acc: 0.4889\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "Current GPU usage: 72%\n",
      "Current GPU usage: 80%\n",
      "Current GPU usage: 81%\n",
      "Current GPU usage: 58%\n",
      "train Loss: 0.4327 Acc: 0.8330\n",
      "val Loss: 2.3954 Acc: 0.4861\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "Current GPU usage: 73%\n",
      "Current GPU usage: 64%\n",
      "Current GPU usage: 62%\n",
      "Current GPU usage: 80%\n",
      "train Loss: 0.4327 Acc: 0.8306\n",
      "val Loss: 2.3188 Acc: 0.4856\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "Current GPU usage: 69%\n",
      "Current GPU usage: 83%\n",
      "Current GPU usage: 73%\n",
      "Current GPU usage: 55%\n",
      "train Loss: 0.4133 Acc: 0.8425\n",
      "val Loss: 2.3209 Acc: 0.4847\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "Current GPU usage: 83%\n",
      "Current GPU usage: 55%\n",
      "Current GPU usage: 55%\n",
      "Current GPU usage: 60%\n",
      "train Loss: 0.4168 Acc: 0.8388\n",
      "Current GPU usage: 67%\n",
      "val Loss: 2.3843 Acc: 0.5037\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "Current GPU usage: 63%\n",
      "Current GPU usage: 60%\n",
      "Current GPU usage: 78%\n",
      "Current GPU usage: 59%\n",
      "train Loss: 0.4175 Acc: 0.8390\n",
      "val Loss: 2.5519 Acc: 0.4880\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "Current GPU usage: 60%\n",
      "Current GPU usage: 69%\n",
      "Current GPU usage: 52%\n",
      "Current GPU usage: 58%\n",
      "train Loss: 0.4065 Acc: 0.8426\n",
      "Current GPU usage: 69%\n",
      "val Loss: 2.7521 Acc: 0.4935\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "Current GPU usage: 83%\n",
      "Current GPU usage: 76%\n",
      "Current GPU usage: 77%\n",
      "Current GPU usage: 85%\n",
      "train Loss: 0.4084 Acc: 0.8427\n",
      "val Loss: 2.4373 Acc: 0.4977\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "Current GPU usage: 65%\n",
      "Current GPU usage: 58%\n",
      "Current GPU usage: 83%\n",
      "Current GPU usage: 81%\n",
      "train Loss: 0.3887 Acc: 0.8523\n",
      "val Loss: 2.7042 Acc: 0.4977\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "Current GPU usage: 62%\n",
      "Current GPU usage: 76%\n",
      "Current GPU usage: 79%\n",
      "Current GPU usage: 76%\n",
      "train Loss: 0.3892 Acc: 0.8491\n",
      "val Loss: 2.7374 Acc: 0.4843\n",
      "Early stopping!\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "Current GPU usage: 61%\n",
      "Current GPU usage: 71%\n",
      "train Loss: 0.5606 Acc: 0.7903\n",
      "val Loss: 2.0553 Acc: 0.4662\n",
      "Early stopping!\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "Current GPU usage: 71%\n",
      "Current GPU usage: 68%\n",
      "train Loss: 0.4611 Acc: 0.8230\n",
      "val Loss: 2.1417 Acc: 0.4958\n",
      "Early stopping!\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "Current GPU usage: 66%\n",
      "Current GPU usage: 57%\n",
      "train Loss: 0.4590 Acc: 0.8200\n",
      "val Loss: 2.2594 Acc: 0.4870\n",
      "Early stopping!\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "Current GPU usage: 71%\n",
      "Current GPU usage: 80%\n",
      "train Loss: 0.4170 Acc: 0.8369\n",
      "val Loss: 2.1232 Acc: 0.4736\n",
      "Early stopping!\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "Current GPU usage: 59%\n",
      "Current GPU usage: 57%\n",
      "train Loss: 0.4444 Acc: 0.8284\n",
      "Current GPU usage: 66%\n",
      "val Loss: 2.1529 Acc: 0.4653\n",
      "Early stopping!\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "Current GPU usage: 54%\n",
      "Current GPU usage: 52%\n",
      "train Loss: 0.4244 Acc: 0.8341\n",
      "val Loss: 2.1191 Acc: 0.4856\n",
      "Early stopping!\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "Current GPU usage: 70%\n",
      "Current GPU usage: 68%\n",
      "train Loss: 0.4501 Acc: 0.8292\n",
      "val Loss: 2.2290 Acc: 0.4713\n",
      "Early stopping!\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "Current GPU usage: 74%\n",
      "Current GPU usage: 83%\n",
      "train Loss: 0.4396 Acc: 0.8301\n",
      "val Loss: 2.0425 Acc: 0.4894\n",
      "Early stopping!\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "Current GPU usage: 80%\n",
      "Current GPU usage: 66%\n",
      "train Loss: 0.4636 Acc: 0.8176\n",
      "val Loss: 2.1739 Acc: 0.4727\n",
      "Early stopping!\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "Current GPU usage: 72%\n",
      "Current GPU usage: 79%\n",
      "train Loss: 0.4351 Acc: 0.8304\n",
      "val Loss: 2.5648 Acc: 0.4481\n",
      "Early stopping!\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "Current GPU usage: 63%\n",
      "Current GPU usage: 69%\n",
      "train Loss: 0.4468 Acc: 0.8269\n",
      "val Loss: 2.0955 Acc: 0.4866\n",
      "Early stopping!\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "Current GPU usage: 68%\n",
      "Current GPU usage: 58%\n",
      "train Loss: 0.4420 Acc: 0.8310\n",
      "val Loss: 2.1521 Acc: 0.4907\n",
      "Early stopping!\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "Current GPU usage: 62%\n",
      "Current GPU usage: 80%\n",
      "train Loss: 0.4241 Acc: 0.8369\n",
      "val Loss: 2.5068 Acc: 0.4750\n",
      "Early stopping!\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "Current GPU usage: 35%\n",
      "Current GPU usage: 54%\n",
      "Current GPU usage: 60%\n",
      "train Loss: 0.4185 Acc: 0.8338\n",
      "val Loss: 2.1217 Acc: 0.4958\n",
      "Early stopping!\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "Current GPU usage: 58%\n",
      "Current GPU usage: 58%\n",
      "train Loss: 0.4690 Acc: 0.8205\n",
      "val Loss: 2.2245 Acc: 0.4620\n",
      "Early stopping!\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "Current GPU usage: 75%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m---> 30\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m         _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m, in \u001b[0;36mCustomModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the tensor\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\models\\inception_resnet_v2.py:293\u001b[0m, in \u001b[0;36mInceptionResnetV2.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    291\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepeat_1(x)\n\u001b[0;32m    292\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixed_7a(x)\n\u001b[1;32m--> 293\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock8(x)\n\u001b[0;32m    295\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2d_7b(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\models\\inception_resnet_v2.py:186\u001b[0m, in \u001b[0;36mBlock8.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    185\u001b[0m     x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch0(x)\n\u001b[1;32m--> 186\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbranch1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x0, x1), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    188\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2d(out)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\layers\\conv_bn_act.py:59\u001b[0m, in \u001b[0;36mConvNormAct.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 59\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 저장\n",
    "num_epochs = 50\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "patience = 12  # 조기 종료를 위한 patience 설정\n",
    "trigger_times = 0  # 조기 종료를 위한 트리거 시간 초기화\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                with amp.autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            trigger_times = 0  # 조기 종료 트리거 초기화\n",
    "            \n",
    "        elif phase == 'val':\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!')\n",
    "                model.load_state_dict(best_model_wts)\n",
    "                dynamic_loader.stop_adjusting()  # 동적 조정 멈춤\n",
    "                exit()  # 학습 종료\n",
    "        \n",
    "        if phase == 'val':\n",
    "            val_loss = epoch_loss  # validation 손실 저장\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    print()\n",
    "\n",
    "print('Training complete')\n",
    "print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model.state_dict(), 'cat_breeds_inception_resnet_v2_1000.pth')\n",
    "\n",
    "# 동적 조정 멈춤\n",
    "dynamic_loader.stop_adjusting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
