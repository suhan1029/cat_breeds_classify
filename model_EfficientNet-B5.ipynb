{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from collections import Counter\n",
    "import torch.cuda.amp as amp\n",
    "from torch import nn, optim\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.model_selection import ParameterSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_usage():\n",
    "    result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], \n",
    "                            stdout=subprocess.PIPE)\n",
    "    return int(result.stdout.decode('utf-8').strip())\n",
    "\n",
    "class DynamicDataLoader:\n",
    "    def __init__(self, dataset, batch_size=32, num_workers=4, pin_memory=True, prefetch_factor=2):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.prefetch_factor = prefetch_factor\n",
    "        self.loader = self.create_loader()\n",
    "        self.adjusting = False\n",
    "        self.target_gpu_usage = 95\n",
    "\n",
    "    def create_loader(self):\n",
    "        return DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, \n",
    "                          pin_memory=self.pin_memory, prefetch_factor=self.prefetch_factor, persistent_workers=True)\n",
    "\n",
    "    def adjust_num_workers(self):\n",
    "        while self.adjusting:\n",
    "            gpu_usage = get_gpu_usage()\n",
    "            print(f\"Current GPU usage: {gpu_usage}%\")\n",
    "            if (gpu_usage < self.target_gpu_usage - 10) and (self.num_workers < 16):\n",
    "                self.num_workers += 1\n",
    "                print(f\"Increasing num_workers to {self.num_workers}\")\n",
    "            elif (gpu_usage > self.target_gpu_usage + 3) and (self.num_workers > 1):\n",
    "                self.num_workers -= 1\n",
    "                print(f\"Decreasing num_workers to {self.num_workers}\")\n",
    "            self.loader = self.create_loader()\n",
    "            time.sleep(20)\n",
    "\n",
    "    def start_adjusting(self):\n",
    "        self.adjusting = True\n",
    "        self.adjust_thread = threading.Thread(target=self.adjust_num_workers)\n",
    "        self.adjust_thread.start()\n",
    "\n",
    "    def stop_adjusting(self):\n",
    "        self.adjusting = False\n",
    "        self.adjust_thread.join()\n",
    "\n",
    "    def get_loader(self):\n",
    "        return self.loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "image_size = 456\n",
    "num_epochs = 50\n",
    "ngpu = 1\n",
    "\n",
    "base_dir = './CatBreeds/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({0: 350, 1: 350, 2: 350, 3: 350, 4: 350, 5: 350, 6: 350, 7: 350, 8: 350, 9: 350, 10: 350, 11: 350, 12: 350, 13: 350, 14: 350, 15: 350, 16: 350, 17: 350, 18: 350, 19: 350})\n",
      "Splitting dataset into training and validation sets...\n",
      "Training and validation data are ready.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 및 증강\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 전체 데이터셋 로드\n",
    "full_dataset = datasets.ImageFolder(base_dir, transform=data_transforms['train'])\n",
    "\n",
    "# 클래스별 이미지 개수 출력\n",
    "class_counts = Counter([full_dataset.targets[i] for i in range(len(full_dataset))])\n",
    "print(\"Original class distribution:\", class_counts)\n",
    "\n",
    "print(\"Splitting dataset into training and validation sets...\")\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataset.dataset.transform = data_transforms['train']\n",
    "val_dataset.dataset.transform = data_transforms['val']\n",
    "\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "print(\"Training and validation data are ready.\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimsu\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kimsu\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B5_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B5_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output features: 460800\n"
     ]
    }
   ],
   "source": [
    "# EfficientNet-B4 모델 로드\n",
    "base_model = models.efficientnet_b5(pretrained=True).to(device)\n",
    "\n",
    "# 모델의 출력 크기를 확인\n",
    "dummy_input = torch.randn(1, 3, 456, 456).to(device)\n",
    "base_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    dummy_output = base_model.features(dummy_input)\n",
    "    num_features = dummy_output.shape[1] * dummy_output.shape[2] * dummy_output.shape[3]\n",
    "    print(f'Output features: {num_features}')\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, base_model, num_classes, dropout):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc = nn.Linear(num_features, num_classes)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def train_and_evaluate(params):\n",
    "    batch_size = params['batch_size']\n",
    "    lr = params['lr']\n",
    "    weight_decay = params['weight_decay']\n",
    "    dropout = params['dropout']\n",
    "\n",
    "    dynamic_loader = DynamicDataLoader(train_dataset, batch_size=batch_size, num_workers=4, pin_memory=True, prefetch_factor=4)\n",
    "    dynamic_loader.start_adjusting()\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=4, persistent_workers=True)\n",
    "    dataloaders = {'train': dynamic_loader.get_loader(), 'val': val_loader}\n",
    "\n",
    "    model = CustomModel(base_model, len(class_names), dropout).to(device)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scaler = amp.GradScaler()\n",
    "    scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(dataloaders['train']), epochs=num_epochs)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    patience = 12\n",
    "    trigger_times = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    with amp.autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                trigger_times = 0\n",
    "            elif phase == 'val':\n",
    "                trigger_times += 1\n",
    "                if trigger_times >= patience:\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    dynamic_loader.stop_adjusting()\n",
    "                    return best_acc\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    dynamic_loader.stop_adjusting()\n",
    "    return best_acc.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating parameters: {'weight_decay': 0.01, 'lr': 0.0001, 'dropout': 0.3, 'batch_size': 32}\n",
      "Current GPU usage: 28%\n",
      "Increasing num_workers to 5\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 0%\n",
      "Increasing num_workers to 6\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 53%\n",
      "Increasing num_workers to 7\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 99%\n",
      "Decreasing num_workers to 6\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 8%\n",
      "Increasing num_workers to 7\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 29%\n",
      "Increasing num_workers to 8\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Validation Accuracy: 0.7885714285714286\n",
      "Evaluating parameters: {'weight_decay': 0.01, 'lr': 0.001, 'dropout': 0.3, 'batch_size': 16}\n",
      "Current GPU usage: 4%\n",
      "Increasing num_workers to 5\n",
      "Current GPU usage: 81%\n",
      "Increasing num_workers to 6\n",
      "Current GPU usage: 86%\n",
      "Current GPU usage: 0%\n",
      "Increasing num_workers to 7\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 92%\n",
      "Current GPU usage: 91%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 83%\n",
      "Increasing num_workers to 8\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 85%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 84%\n",
      "Increasing num_workers to 9\n",
      "Current GPU usage: 84%\n",
      "Increasing num_workers to 10\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 92%\n",
      "Current GPU usage: 82%\n",
      "Increasing num_workers to 11\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 86%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 83%\n",
      "Increasing num_workers to 12\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 92%\n",
      "Current GPU usage: 91%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Validation Accuracy: 0.7921428571428571\n",
      "Evaluating parameters: {'weight_decay': 0.001, 'lr': 0.0001, 'dropout': 0.7, 'batch_size': 16}\n",
      "Current GPU usage: 0%\n",
      "Increasing num_workers to 5\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 1%\n",
      "Increasing num_workers to 6\n",
      "Current GPU usage: 86%\n",
      "Current GPU usage: 88%\n",
      "Current GPU usage: 84%\n",
      "Increasing num_workers to 7\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 92%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 37%\n",
      "Increasing num_workers to 8\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 86%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 77%\n",
      "Increasing num_workers to 9\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 86%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 89%\n",
      "Current GPU usage: 92%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 91%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 91%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 85%\n",
      "Current GPU usage: 87%\n",
      "Current GPU usage: 91%\n",
      "Current GPU usage: 89%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 89%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 88%\n",
      "Current GPU usage: 92%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 82%\n",
      "Increasing num_workers to 10\n",
      "Current GPU usage: 87%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 73%\n",
      "Increasing num_workers to 11\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 89%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 88%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 90%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 91%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 27%\n",
      "Increasing num_workers to 12\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 86%\n",
      "Current GPU usage: 85%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 84%\n",
      "Increasing num_workers to 13\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 84%\n",
      "Increasing num_workers to 14\n",
      "Current GPU usage: 77%\n",
      "Increasing num_workers to 15\n",
      "Current GPU usage: 89%\n",
      "Current GPU usage: 92%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 91%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 92%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 90%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 41%\n",
      "Increasing num_workers to 16\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 87%\n",
      "Validation Accuracy: 0.8221428571428572\n",
      "Evaluating parameters: {'weight_decay': 0.001, 'lr': 0.0001, 'dropout': 0.3, 'batch_size': 32}\n",
      "Current GPU usage: 1%\n",
      "Increasing num_workers to 5\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 3%\n",
      "Increasing num_workers to 6\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 1%\n",
      "Increasing num_workers to 7\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 76%\n",
      "Increasing num_workers to 8\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Validation Accuracy: 0.8335714285714285\n",
      "Evaluating parameters: {'weight_decay': 0.01, 'lr': 0.001, 'dropout': 0.7, 'batch_size': 16}\n",
      "Current GPU usage: 4%\n",
      "Increasing num_workers to 5\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 92%\n",
      "Current GPU usage: 0%\n",
      "Increasing num_workers to 6\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 85%\n",
      "Current GPU usage: 90%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 87%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 82%\n",
      "Increasing num_workers to 7\n",
      "Current GPU usage: 75%\n",
      "Increasing num_workers to 8\n",
      "Current GPU usage: 93%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 86%\n",
      "Current GPU usage: 75%\n",
      "Increasing num_workers to 9\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 95%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 90%\n",
      "Current GPU usage: 77%\n",
      "Increasing num_workers to 10\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 73%\n",
      "Increasing num_workers to 11\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 91%\n",
      "Current GPU usage: 89%\n",
      "Current GPU usage: 94%\n",
      "Current GPU usage: 83%\n",
      "Increasing num_workers to 12\n",
      "Validation Accuracy: 0.8114285714285714\n",
      "Best parameters: {'weight_decay': 0.001, 'lr': 0.0001, 'dropout': 0.3, 'batch_size': 32}\n",
      "Best validation accuracy: 0.8335714285714285\n"
     ]
    }
   ],
   "source": [
    "# 이 셀은 2시간 30분정도 걸림\n",
    "\n",
    "param_dist = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'lr': [0.001, 0.0001, 0.00001],\n",
    "    'weight_decay': [0.01, 0.001, 0.0001],\n",
    "    'dropout': [0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "param_list = list(ParameterSampler(param_dist, n_iter=5, random_state=42))\n",
    "\n",
    "best_params = None\n",
    "best_acc = 0.0\n",
    "\n",
    "for params in param_list:\n",
    "    print(f\"Evaluating parameters: {params}\")\n",
    "    acc = train_and_evaluate(params)\n",
    "    print(f\"Validation Accuracy: {acc}\")\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation accuracy: {best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU usage: 19%\n",
      "Increasing num_workers to 5\n"
     ]
    }
   ],
   "source": [
    "# 최적 하이퍼파라미터로 최종 모델 학습 및 저장\n",
    "best_batch_size = best_params['batch_size']\n",
    "best_lr = best_params['lr']\n",
    "best_weight_decay = best_params['weight_decay']\n",
    "best_dropout = best_params['dropout']\n",
    "\n",
    "dynamic_loader = DynamicDataLoader(train_dataset, batch_size=best_batch_size, num_workers=4, pin_memory=True, prefetch_factor=4)\n",
    "dynamic_loader.start_adjusting()\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_batch_size, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=4, persistent_workers=True)\n",
    "dataloaders = {'train': dynamic_loader.get_loader(), 'val': val_loader}\n",
    "\n",
    "model = CustomModel(base_model, len(class_names), best_dropout).to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=best_lr, weight_decay=best_weight_decay)\n",
    "scaler = amp.GradScaler()\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=best_lr, steps_per_epoch=len(dataloaders['train']), epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 5%\n",
      "Increasing num_workers to 6\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 51%\n",
      "Increasing num_workers to 7\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 97%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 96%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Current GPU usage: 98%\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Early stopping!\n",
      "Training complete\n",
      "Best val Acc: 0.833571\n"
     ]
    }
   ],
   "source": [
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "patience = 12\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                with amp.autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            trigger_times = 0\n",
    "        elif phase == 'val':\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!')\n",
    "                model.load_state_dict(best_model_wts)\n",
    "                dynamic_loader.stop_adjusting()\n",
    "                exit()\n",
    "\n",
    "        if phase == 'val':\n",
    "            val_loss = epoch_loss\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print('Training complete')\n",
    "print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model.state_dict(), 'cat_breeds_efficientnet_b5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동적 조정 멈춤\n",
    "# dynamic_loader.stop_adjusting()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
